# Buggy Diary – March-01

This is the first entry of the Buggy Diary which will (hopefully) feature regular updates
on the development of the [Buggy System](https://github.com/BuggyOrg).

# Active development

This section will feature the active projects and what happened in the last iteration (~last month). And a short prospect on what is currently in the pipeline.

## Graphtools

The basic graph implementation got several vital updates in the last iteration. The most recent version is 0.4.0-pre.28.

--------------------------------
|Feature| Short Description & Progress |
|-------|----------------------|
|debugging|Regarding the debugging possibilities, a new function `debug` is exported since [0.4.0-pre.27](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.27). Furthermore safe guards were inserted in multiple functions to prevent strange `'path' undefined` problems when an input was not set correctly. |
|Graph API|The function `replacePort` was ported from the `rewrite` module into graphtools and is part of the API since [0.4.0-pre.27](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.27). |
|Flow API| The `namedFlow` function was deprecated and the old method of handling context information in a flow function was changed to a more Haskell-let like method.|
|Basic Rewriting|A set of functions for rewriting was added, that allow easier handling of compounds and lambda functions.|
|Algorithm| A function for computing the [lowest common ancestor (LCA)](https://en.wikipedia.org/wiki/Lowest_common_ancestor) was added. The topological sorting can now print the graph layer in which a loop was found.|
|Connections| Methods for successors and predecessors now have an option for handling compound nodes.|
|Documentation| A few functions like addNode and similar got a more precise documentation and some examples to easily see how it should be used.|
---------------------------------------------------

### Debugging

A bunch of methods now check if their input graph is valid (i.e. an okay object). This prevents
a handful of problems while debugging. You should get more understandable error messages
out of graphtools now, if not please file an issue and/or create a in graphtools test that asserts a understandable error message. Feel free to fix it, there is a method `assertGraph` in `src/assert.js` that tries to find the name of the caller, gets the position of the argument and checks the given graph. This could and should be extended to more than graphs.

A newly exported method is the `Graph.debug` method that prints the graph if the `DEBUG` environment variable is set to `debug-graph` (see [npm-debug](https://www.npmjs.com/package/debug) for detailed information on how this works). The program `debug-graphs` in the buggy-meta project scans the stderr output and opens for every graph output a new tab in your browser (be cautious to not open too many tabs). This is definitely improvable but helps a lot to visualize graphs on the fly. The command line for doing so could look like this:

```
DEBUG=debug-graph npm test 2>&1 | debug-graphs
```

The new update of VSCode merged the debugger `node2` into the `node` debugger. Automatic detection does not seem to work for us. To make it work you also have to set the `protocol` to `"inspector"` in the `launch.json` like this:

```json
  "type": "node",
  "protocol": "inspector",
```

### Graph API

A few minor changes were introduced to the basic graph API (excluding flow changes which are detailed below). Most importantly the function `replacePort` was added. It takes only the port which you want to change, the new port and the graph. It is not necessary to specify the node of the port as the node is (should) always be part of the port itself. Please keep this in mind when designing functions that somehow work with ports. You can always get the node of the port via `Graph.node(port, graph)`.

Another important change is the clear distinction between `edges` and `edgesDeep`. Before this change `edges` returned all edges on all layers. Now the `edges` method only returns the edges of the current (compound) node, whereas `edgesDeep` will return all edges below the given compound node. This change is in the API since [0.4.0-pre.22](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.22) make sure to update your code for that.

A new function since [0.4.0-pre.21](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.21) is `Graph.isomorph` which checks if two graphs are isomorph, i.e. they encode the exact same structure. This includes all nodes with their componentIDs and parameters (but not IDs), all edges and all defined components. With one key restriction. They must do something inside the graph. Floating nodes/subgraphs are ignored (a floating nodes/subgraphs are not connected to the rest of the graph). This means, that a graph with only one unconnected `math/add` node is isomorph to a graph that has a single unconnected `math/const` nodes. Those nodes are ignored. The isomorphy does not care for modifications that do nothing to the semantics of the graph. This introduced some problems with the current rewrite tests as those have no connecting edges to the root node, i.e. they all had only floating nodes. This meant, that graphs were always isomorph. Those cases will never occur in real world examples and are easily fixable by connecting the output to the output of the root node (isomorphy does not care for nodes that are connected to the output)

### Flow API

The function `namedFlow` was used to get better debugging information on flow functions and which function was executed. There were some issues with interleaving the names and functions. The new way of defining descriptions and a name for the flow is by adding an descriptor object as the last parameter to flow. This can include a name for the flow function and separate names for every function.

```javascript
Graph.flow(
  Graph.addNode({...}),
  Graph.addEdge({...}),
  {name: 'Do stuff', names: ['Adding a node', 'Adding an edge']}
)()
```

The major API change occurred in [0.4.0-pre.24](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.24) where the old clunky mechanism for handling results of previous *graph actions* (fancy name for a function that takes a graph and returns a graph `Graph → Graph`) was handles in a special function with strange implications that no one could ever really understand ;). The new way of handling context information is based on Haskells do notation where they use let to process extra information. Sadly JS does not support an fancy syntax like Haskell so we have to use callbacks. The new let syntax looks like this:

```javascript
Graph.flow(
  Graph.let(
    Graph.addNode({...}),
    (newNnode, graph) => {
      console.log(newNode)
      return graph
    }
  ),
  ...
)
// for multiple context calls
Graph.flow(
  Graph.let(
    [
      Graph.addNode({...}),
      Graph.addNode({...})
    ],
    ([node1, node2], graph) => {
      console.log(node1, node2)
      return Graph.removeNode(node2, graph)
    }
  ),
  ...
)
```

With the rewrite every context generating *graph action* has a callback function that call be used explicitly without a let.

```javascript
// equivalent to the first flow method above
Graph.addNode({...}, (newNode, graph) => {
  console.log(newNode)
  return graph
})
```

To create a function that creates context information one has to call the given context. A *graph action* could be defined like the following:

```javascript
export const newGraphAction = curry((data, graph, ...cbs) => {
  const cb = Graph.flowCallback(cbs)
  const [contextData, newGraph] = doStuff(data, graph)
  return cb(contextData, newGraph)
})
```

There are a few important things to note:

 1. The *graph action* is a curried function. This is an absolute must! In some situations it is necessary to have a curreid function.
 2. The curried function gets an optional number of arguments `...cbs`. It is absolutely vital to the function to define the callback like this or otherwise it is not possible to call the `newGraphAction` without an callback (like a normal developer would hope to). The curryign cannot be smart about the usage so we must...
 3. The callback function is extracted from the `cbs` array via `Graph.flowCallback`. This is also an absolute must, some methods rely on a special treatment of callbacks (e.g. for error handling, so we know when you forget to call a vital callback).
 4. Call the callback! The callback must always return a graph and it always takes exactly two arguments, the context and the graph. Not more, not less (well there is the possibility to pass an callback as an optional parameter after the graph, but that is only interesting in very few cases.. e.g. sound error handling).

 In future it is possible that a special function for defining graph actions will be added to the Graph API to remove those **very possible** pitfalls (Yup I tripped a few times into those pitfalls and it cost me bit of time to get used to it).

Besides the new let function there are a few other new functions that could help reduce complexity in the end. One is the `Graph.sequential` function that gets a list of *graph actions* with contexts and every function in the sequence that produces a context will hand this (and the new graph) to the next function in the sequence. Now we can build really fancy functions.

```javascript
Graph.sequential([Graph.addNode({...}), Graph.removeNode])(Graph.empty())
```

This adds a node and removes it immediately afterwards. Note that the first function in the sequence is special as it will not get context information (`Graph.addNode: Node x Graph → Graph`).

Another new function is `distribute` which simply distributes a value over multiple functions and then uses another method to call the functions like for example `sequential`. This function still produces some headaches as it does not play nice with anything. The following snippet will demonstrate its usage.

```javascript
const distSeq = Graph.distribute(Graph.sequential)
// take a subset of nodes and turn it into a lambda function
export const replaceByCall = curry((subset, graph) =>
  convertToLambda(subset, graph, distSeq([createInputPartials, ternaryPack(createCall)])))
```

In this example we get a subset of nodes and create a lambda function out of them using `convertToLambda`. After this the lambda node floats in the graph with no connections to the outside world. We use `createInputPartials: LambdaContext x Graph → Graph` to use the context information from `convertToLambda` and create for every input to the `subset` an partial application. The `distribute` handles passing the context to `createInputPartials`. The `sequential` function then calls the first method in the list. The `createInputPartials` function now wants to pass its context information (i.e. the last partial that resolved the last input) to the next call via sequential, but distribute already passed its information to `createCall`. That's a bummer.. we cannot pass both informations unless we can. And `createCall` exactly awaits two information, **but** (and this is an important bold-face **but**) we must have the following signature for the `createCall` function: `Context x Graph → Graph`. This is the least headachy solution. So `createCall` is defined as:

```javascript
const createCall = ([context, fnNode], graph) =>
  ...
```

The first parameter is an array with the `context` we get from `convertToLambda` and the `fnNode` from `createInputPartials` (which can be the lambda function if the lambda function is a thunk / nullary). Now... the `distribute` would apply one argument and the `sequential` would apply two arguments, but `createCall` only accepts two arguments (and only should accept two arguments). That is why we used `ternaryPack` in the `distribute` example above. The `ternaryPack` takes the three arguments and bundles the first two arguments into an array.

So why not simply allow for 3 arguments. One key problem was the partitioning into useful functions. `replaceByCall` is not defined as above, but uses `replaceByThunk` like this:

```javascript
export const replaceByCall = curry((subset, graph) =>
  replaceByThunk(subset, graph, createCall))
```

The third argument to `replaceByThunk` is the callback (after `replaceByThunk` is finished). Unfortunately calling replaceByThunk without a callback (which is possible) would yield the default callback (via `Graph.flowCallback`) and that has 2 arguments. Together with the currying of optional and non-optional arguments a lot of (error prone) logic would be necessary to accommodate for those ternary functions.

### Basic rewriting

A few common rewriting rules are gathered in graphtools. This is partly due to the fact that those need internal methods of graphtools that are not exported at the moment. The newly exported `addNodeWithID` could change this. One example is the `includePredecessor` function that must ensure, that the ID of the predecessor does not change when embedding it in the compound and removing it from the parent node. The change to `addNodeWithID` is rather recent (since [cd9191a5b9...](https://github.com/BuggyOrg/graphtools/commit/cd9191a5b98dd669698bc82ebac1d126342cf24b)). Major updates were rewrite functions that allow to create compound out of subsets of nodes via `compoundify`. Methods like `convertToLambda` use these methods at their core. The newly exported method `replaceByCall` is probably rather uninteresting as adding additional partials and calls makes programs not more efficient, but `replaceByThunk` is vital for the implementations of ifs in recursive nodes. See changes in *rewrite-toolchain*.

### Algorithm


**Topological Sort**

The topological sort got a minor upgrade to enable easier debugging. When it finds a loop it is possible to print the corresponding loop onto the terminal. It currently prints a dot-file that can be visualized with graphviz. Simply activate `DEBUG=debug-graph` to see the graph.

**Lowest Common Ancestor**

A new algorithm is the lowest-common-ancestor (LCA). Using the algorithm of Bender et al. 2005 (doi:[10.1016/j.jalgor.2005.08.001](https://dx.doi.org/10.1016%2Fj.jalgor.2005.08.001)). One important notion of our implementation is that we only search inside the current compound for the lowest-common-ancestor. We probably never need more than that, and if we don't want to be restricted by compound borders `decompoundify` will do the work. For recursive nodes the semantics differ and simply breaking out of an recursive node will probably not do what is intended. LCA is currently rather slow, Benders algorithm can be improved by a lot, but there are other changes to come that could improve the performance significantly.

**Deep Predecessors Search**

Accompanying LCA are a few *deep* predecessor methods that use predicate functions or an array of nodes to determine when to stop looking for further predecessors. It will return all nodes in between. These functions are accessible via `Algorithm.predecessorsUntil(nodes, predicate, graph)` and `Algorithm.predecessorsUpTo(nodes, stopNodes, graph)`. The first method uses a predicate function to determine when to stop, the second one an array of nodes. Both functions either take one node/location or an array of those. An important caveat: When `nodes` contains a location identifying the input port of a node, the node will not be part of the result. If `nodes` contains a location identifying a node, the node will be part of the result.

### Connections

In most situations looking for predecessors and successors is only interesting on the current hierarchy layer. Since [0.4.0-pre.27](https://github.com/BuggyOrg/graphtools/releases/tag/v0.4.0-pre.27) the methods `Graph.predecessors` and `Graph.successors` will not go into compound nodes. There is an optional attribute on the function to re-enable going into compound nodes.

```
Graph.predecessors(node, graph) // will only look on the current layer
Graph.predecessors(node, graph, true) // will also go into compounds

Graph.successors(node, graph) // will only look on the current layer
Graph.successors(node, graph, true) // will also go into compounds
```

This flag is only sensible when the first parameter to `predecessors` or `successors` is a node. If it is a port it is clear what its predecessors/successors are.

### Current and future work

**Better error messages**

The most important part right now is the implementation of sane safe-guards
in the API functions. Error messages are mostly awful and usually don't
help finding the errors. Most of this is part of the next iteration.

**Performance improvements**

Right now the performance is bad but usually not noticeable due to the small
example sizes. This mostly due to the following (only guessing not based on data):

 - Queries always go through every node and do not use acceleration
   structures. This affects nearly all methods in the API as all of them
   use location based queries. The performance gain for implementing those could
   be huge, but also could include a lot of logic to keep the acceleration
   structures up to date.
 - All changes copy the graph. The functional design currently leads to
   lots of copies that are mostly unnecessary.

This will probably change in a few month as there is a new BA that will
look exactly at the performance of the graph implementation. Due to the monadic
design it is probably possible to minimize the copying to a minimum (Applicative
monads allow to put the side effect last and all in between operations can be
done in-place). Start of the BA is probably in April.

**Cleanup**

The rewrite methods should probably be in another package. It is possible that
they will soon move into another repository.

## Buggy-CLI

The Buggy-CLI got a major redesign in the last months. The goal is to decouple
the CLI from the releases of all the other packages. The main goal for the
CLI is to pipe the right data into the right tool to achieve the desired effect.

The CLI is in an unfinished state and needs some of work to get on track.
Currently it is based on a toolchain (which is predefined). The toolchain
consists of tools that are essentially programs that take some input
and produce some output. Like *Lisgy* that *consumes* `.clj` files and
*produces* a portgraph. The toolchain definition is very rigid at
the moment. All tools are defined inside the buggy-cli project
(`src/toolchain.js`). There are three different types of tools that are
supported.

 1. NPM packages that export a CLI. But only the first exported cli is used
   (well which is a random one as the `bin` field is a JSON object and has
   no inherent order. There is certainly room for improvement here ;) ).
 2. Hard coded JavaScript.

Tools are stored as JS-objects that have the following form:

```json
{
  "name": "...",
  "consumes": "<input-type>",
  "produces": "<output-type>",
  "module": "[only for NPM packages (type 1)]",
  "args": "[arguments for NPM package binaries (type 1)]",
  "activatedBy": "[only for input-tools determines whether this can parse the input]",
  "command": (input) => "[the hard coded javascript (type 2)... this must be a JS function]",
  "depends": ["<other-tool>"]
}
```

Buggy-CLI installs all NPM modules inside the users home directory. It also
tries to find fitting versions (using graphtools versions that are compatible
etc.). It will parse the input, select the correct tool (if any) to parse
the input. After that it will find a possible chain of tools that generates the
expected output format. After choosing all translator tools the CLI
tries to fulfill all given constraints. This completes the toolchain. This
toolchain is now used to transpile the input into the fitting output.

### Current and future work

There are several important features that need more attention.

**Not so rigid toolchain**

The CLI tool is in itself rather powerful as it can create a toolchain that
gets the output and which fulfills all constraints. But it is not possible
to extend the toolchain without changing it in the Buggy-CLI repository.
The toolchain is currently simply an array of tools handed to Buggy-CLI on start.
It should be fairly simple to extend the array with further tools dynamically.
One drawback is, that this restricts the usage of JS code as the only
possibility to use JS code is to bundle everything into the `"command"` function
or to crate a CLI that is called.

**Use a JS API directly**

There are currently two methods of defining a tool, via an CLI tool (registered
in the NPM registry) and simple JS code. It would be interesting to use the
API of those NPM packages directly to reduce startup time. Every CLI tool
has to spawn a node instance, parse the command line arguments, parse
the graph JSON, process it and then print a string representation of the result.
The spawning, parsing and `stringify` part could be avoided completely. This
would reduce the transpilation time by a lot.

**More constraints**

Buggy-CLI knows the `depends` constraint and thats all. The typesystem tool that
adds constructors / destructors and other type-related functions must run
before `resolve` but it would be strange to define a dependency relation
in `resolve` on the typesystem as resolve can work without the typesystem itself.

**Possibility for non NPM tools**

It would be very handy, especially for debugging purposes, to use local
versions of some packages to see if everything is performing well, before
publishing the package.

**Library host is broken**

It is only possible to set the library host via 

**Updating the Cache**

The CLI uses information from NPM to decide which tool to use. But
those queries are not cheap and add up. That is why Buggy-CLI uses
an internal cache. But this cache must be updated from time to time.
Updating this cache is done via the command line parameter: `-u`
but this parameter is not available in the API. It is possible to
remove the cache or to hand the new cache-update provider.

**Error message are horrible**

The error messages that Buggy-CLI produces are horrible. There should be a clear
indication of which tool failed and why. We have to rely on the error message
of the tool but it should be presented in a more readable way.

### Discussion

A different approach to the current `activatedBy` was suggested
by MM. Instead of selecting one way for the toolchain.

## Typify

The typify tool takes a graph that has some type information and propagates those
information to neighboring ports / nodes to replace all type variables and have
a fully typed graph. It usually comes directly after resolving. Until
now *Typify* knew only one type variable, namely `generic`. All other types
were "real" types.

### Active development

**Different Typenames**

The goal of this is extending the `generic` typename to "as many as you want" typenames.
They are assigned not by overwriting, but by an direct assignment. We will export special
functions that allow getting the types for a port that respect those assignments.

**Complex Types**

Types like lists consist of more than a primitive type. A list in lisgy could look like this.

```clojure
(deftype (List a) [NIL (Cons a (List a))])
```

Or as an object in the JSON graph.

```json
{
  "typeDefinition": {
    "name": "or",
    "data": [
      {
        "type": "NIL"
      },
      {
        "name": "Cons",
        "data": [
          {
            "type": "a"
          },
          {
            "name": "List",
            "data": [
              {
                "type": "a"
              }
          }
      }
  }
}
```

Those were added but not yet released as an NPM package. They will land in 0.1.6.

## Typesystem

We added a new tool to our toolchain that creates necessary accessor functions and
constructors / destructors to data types. This tool must run before resolve as it only
generates components which get replaced where they are needed. That has the benefit of
reducing the size of the output.

**Constructors**

For a type like the list type the *Typesystem* tool will generate a function that
creates the type itself. For the following list type:

```clojure
(deftype Pair (StringPair String String))
```

it will create a function `StringPair: String x String → StringPair ⊑ Pair`.
You can use it simply in Lisgy

```clojure
(StringPair "Hello" "World")
```

**Destructors**

If you want to extract values out of a type you can use a destructor. Those
are defined as `de-<TypeName>-<ArgNumber>` so the following example would
yield `"Hello"`:

```clojure
(de-StringPair-0 (StringPair "Hello" "World"))
(de-StringPair-1 (StringPair "World" "Hello"))
```

### Current and future work

**Enable pattern matching**

To eliminate the need for the `de-` names to extract values in types a
pattern matching scheme would be added that could transform expressions like:

```clojure
(match sp (StringPair a b) (concat a b))
```

into:

```clojure
(let [a (de-StringPair-0 sp)
      b (de-StringPair-1 sp)])
```

It is unclear how much Lisgy help is necessary to implement this.

**Recursive data structures**

Recursive data structures are nearly finished. This will probably
be part of the next iteration. One missing feature is the "join" or
the distinction between different specializations (like `NIL` and `Cons`
in the list example above).

## Lisgy

In the last few months Lisgy got a major rewrite. The parser is currently
being rewritten to support better error messages with line and column numbers
and a cleaner interface between parsing and graph generation.

### Support for Types

Lisgy got support for defining types via `deftype` 

### Current and future work

**Completing the transition to the new parser**

The new parser is not yet part of lisgy but should.

## Graphify

Graphify had no major changes in the past but would need
a few updates.

### Future work

A programming assignment created a few postprocessing tools
that allow adding edges after layouting and adding labels
to edges. One particular feature that is still not
implemented is adding labels to ports.

## Rewrite / Rewrite-Toolchain

Graph rewriting is a central part of Buggy. The *Rewrite* package
got an API update in the last two weeks. Rules are now
an object with at least the attributes: `matcher`,
`generator` and `set`. Rules can have further attributes like
the `name` of the rule. Another change is the use of
`Graph.isomorph` for checking if the graph has changed due to some
rewrite rule. A graph is isomorph if it has the same semantics
but might differ in the IDs von nodes.

A new repository, the *Rewrite-Toolchain* was added. The
intention is to have a collection of rewrite rules that
are added to the CLI toolchain. Those rules would need
more information like constraints (e.g. after resolve,
before typify). The API should export a toolchain that is loaded
by Buggy-CLI in the best case.

### Future work

**Performance Improvement**

Checking if the graph changed is a bit much. Simply passing the
information if any rule was applied should suffice. This could
be done by changing the return value of `apply` to not only
return the new graph, but also if a rule was applied and
ideally what rule applied.

## Codegen

The *Codegen* project replaces the old *Gogen* project. It not only creates
go code, but also every other kind of programming language code. The code generation
uses language definitions that each can contain code for atomics and some general
templating functions plus helper functions. To reduce the complexity of those
templates, *Codegen* supports multiple language definitions at once. Each language
definition can extend or overwrite previous definitions. They also can define an
activation function to ensure, that they only are active in certain conditions.
One example could be, that each edge that has the flag `debug` set in their
metaInformation should print all values that go over the edge. The easiest way
of defining such a language extension is by creating an activation function
that checks the `debug` value for every edge and if it is set, returns `true`.

### Future and active work

**MT Parallel Code Generation**

PU currently works on a system to enable parallel execution for Buggy programs.
The system should automatically detect which parts are parallelizable and with the
right language extension, the generated code will run parallel code. Due date is July 2017.

**Support for Lambda Functions**

*Codegen* has no support for Lambda functions and their execution. This is necessary to
implement `if` as `if` must not evaluate one of the input branches. This is done
via lambda functions. Each input branch is converted into a thunk and the
if node executes only the correct branch. This is currently under development and should
be ready in the next iteration.

**Support for Recursions**

Recursions are not yet supported as they rely on a working `if` implementation. Without
an `if` the recursion cannot stop. This is probably rather simple after the `if` works.

**Support for Recursive Types**

*Codegen* already supports complex types, constructors and destructors. But it is
unclear if those methods also word for recursive types like lists. It is possible that
this will work without modifying anything. This depends on the [*Typesystem* recursive
datastructures](#typesystem).

## Coptify

A new project is *Coptify*. The semantic of an branching edge is that the data must
be copied before the following processes can work with the data. This has the
disadvantage, that we have to copy the data for every edge. *Coptify* analyzes the
graph and according to the meta information of atomic nodes tries to minimize
necessary copies. This project is in its early stages and there will be some updates
in the upcoming iterations.